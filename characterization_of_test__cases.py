# -*- coding: utf-8 -*-
"""Characterization_of_test _cases.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eUvgN5vNEr6Or7jolMFfASstJrWePa7t
"""

import requests
import csv
import os

# Base URL for GitHub API
GITHUB_API_URL = "https://api.github.com/search/repositories"

# Simplified Query without exclusions for testing
SEARCH_QUERY = 'stars:>100 forks:>50 pushed:>=2022-09-17 language:python language:java'

# Exclusion keywords
EXCLUDE_KEYWORDS = ["toy", "sample", "example", "projects", "demo", "tutorial", "project"]

# GitHub token
TOKEN = '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'

# Headers for authenticated requests
HEADERS = {
    'Accept': 'application/vnd.github.v3+json',
    'Authorization': f'token {TOKEN}'
}

# Function to check if the repository has unit tests
def check_for_unit_tests(repo):
    test_directories = ['test', 'tests', 'src/test', 'unittest']
    contents_url = repo['contents_url'].replace("{+path}", "")
    response = requests.get(contents_url, headers=HEADERS)
    if response.status_code == 200:
        files = [item['name'] for item in response.json()]
        if any(test_dir in files for test_dir in test_directories):
            return True
        return False

# Function to search repositories based on the query, extracting all pages
def search_repositories():
    repositories = []
    page = 1
    per_page = 50  # Number of results per page (max 100)
    while True:
        query_url = f"{GITHUB_API_URL}?q={SEARCH_QUERY}&per_page={per_page}&page={page}"
        response = requests.get(query_url, headers=HEADERS)
        if response.status_code == 200:
            result_data = response.json()
            fetched_repos = result_data.get('items', [])

            # Filter repositories
            for repo in fetched_repos:
                # Ensure the repo description exists before checking for keywords
                description = repo['description'] or ""
                if not repo['fork'] and not any(keyword in repo['name'].lower() or keyword in description.lower()
                                                for keyword in EXCLUDE_KEYWORDS):
                    repositories.append(repo)
            if len(fetched_repos) < per_page:  # No more results to fetch
                break
            page += 1
        else:
            print(f"Failed to retrieve repositories: {response.status_code}")
            print(response.json())
            break
    return repositories

# Function to generate CSV with project details
def generate_csv(repositories):
    with open('github_projects_token.csv', mode='w', encoding='utf-8') as file:
        writer = csv.writer(file)
        # Keep the header with "Does the project execute or run" but leave this field empty
        writer.writerow(['Project Name', 'Project Link', 'Does the project execute or run', 'Does the project unit tests run'])

        for repo in repositories:
            project_name = repo['name']
            project_url = repo['html_url']
            has_tests = check_for_unit_tests(repo)

            writer.writerow([project_name, project_url, '', 'Yes' if has_tests else 'No'])

# Main function to execute the script
def main():
    print("Searching for repositories...")
    repositories = search_repositories()
    if repositories:
        print(f"Found {len(repositories)} repositories. Generating CSV file....")
        generate_csv(repositories)
        print("CSV file generated: github_projects_token.csv")
    else:
        print("No repositories found")

if __name__ == '__main__':
    main()



import pandas as pd

python_csv = pd.read_csv("/content/github_projects_token.csv")
python_csv.head()

filtered_python = python_csv[python_csv['Does the project unit tests run'] == 'Yes']
filtered_python.to_csv("/content/github_projects_python.csv", index=False)

java_csv = pd.read_csv("/content/github_projects_token_key.csv")
java_csv.head()

filtered_java = java_csv[java_csv['Does the project unit tests run'] == 'Yes']
filtered_java.to_csv("/content/github_projects_java.csv", index=False)

